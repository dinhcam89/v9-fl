# Federated Learning Performance Analysis Report
Client ID: client-0
Wallet Address: 0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe
Generated: 2025-05-26 02:50:25
====================================================================================================

## Dataset Information
--------------------------------------------------
Total Original Samples: 0
Total Features: 0

### Data Split Distribution
├── Training Set:   0 samples
├── Validation Set: 0 samples
└── Test Set:       0 samples

### Fraud Case Distribution
**Training Set (0 samples):**
  ├── Fraud Cases:  0 (0.00%)
  └── Normal Cases: 0 (100.00%)

**Validation Set (0 samples):**
  ├── Fraud Cases:  0 (0.00%)
  └── Normal Cases: 0 (100.00%)

**Test Set (0 samples):**
  ├── Fraud Cases:  0 (0.00%)
  └── Normal Cases: 0 (100.00%)

## Session Information
--------------------------------------------------
Session Start: 2025-05-25 17:12:07 UTC
Session End:   2025-05-26 02:50:24 UTC
Duration:      09:38:17
Total Rounds:  5

## Validation Set Performance Summary
--------------------------------------------------
 round       phase   loss accuracy precision recall f1_score  tp   tn  fp  fn
     1    Training 0.0266   99.89%    63.64%  87.5%   73.68%  14 9469   8   2
     2 Fine-tuning 0.0185   99.89%    63.64%  87.5%   73.68%  14 9469   8   2
     3 Fine-tuning 0.0264   99.89%    63.64%  87.5%   73.68%  14 9469   8   2
     4 Fine-tuning 0.0179   99.91%    66.67%  87.5%   75.68%  14 9470   7   2
     5 Fine-tuning 0.0144   99.91%    66.67%  87.5%   75.68%  14 9470   7   2

## Test Set Performance Summary
--------------------------------------------------
 round       phase   loss accuracy precision recall f1_score  tp    tn  fp  fn
     1    Training 0.0263   99.91%    66.67% 96.97%   79.01%  32 18939  16   1
     2 Fine-tuning 0.0182   99.88%    60.78% 93.94%   73.81%  31 18935  20   2
     3 Fine-tuning 0.0258   99.92%    68.09% 96.97%    80.0%  32 18940  15   1
     4 Fine-tuning 0.0170   99.92%    69.57% 96.97%   81.01%  32 18941  14   1
     5 Fine-tuning 0.0138   99.92%    69.57% 96.97%   81.01%  32 18941  14   1

## Global Model Evaluation Summary
--------------------------------------------------
 round   loss accuracy precision recall f1_score  tp    tn  fp  fn  score  rank  reward
     1 0.0195   99.92%    68.09% 96.97%    80.0%  32 18940  15   1    0.0     0     0.0
     2 0.0242    99.9%     64.0% 96.97%   77.11%  32 18937  18   1    0.0     0     0.0
     3 0.0261   99.91%    66.67% 96.97%   79.01%  32 18939  16   1    0.0     0     0.0
     4 0.0153   99.93%    72.73% 96.97%   83.12%  32 18943  12   1    0.0     0     0.0
     5 0.0239   99.92%    68.09% 96.97%    80.0%  32 18940  15   1    0.0     0     0.0

## Performance Insights
➡️  Recall remained stable at 97.0%
🏆 Best performance in Round 1 with score 0
📊 Average contribution score: 0