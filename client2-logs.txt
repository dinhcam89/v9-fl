>   --ensemble-size 8 \
>   --ga-generations 2 \
>   --ga-population-size 6 \
>   --contract-address 0x47e7A7FAb1aEf8994b9b767E8743239D606a749A \
>   --wallet-address 0x73CDd275BeB83388A2eB8A6b10C5E1Db7b1f1e0b \
>   --train-file ./data/client-2_train.txt \
>   --test-file ./data/client-2_test.txt \
>   --client-id client-2
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
2025-05-14 17:27:47,633 - federated.ipfs - INFO - Connected to IPFS node version: 0.34.1
2025-05-14 17:27:47,634 - FL-Client-Ensemble - INFO - Initialized IPFS connector: http://127.0.0.1:5001/api/v0
Using Ganache account: 0x1D5102A04086332530dbBf906F6D7290EE9302e6
Contract loaded at address: 0x47e7A7FAb1aEf8994b9b767E8743239D606a749A
2025-05-14 17:27:47,680 - FL-Client-Ensemble - INFO - Initialized blockchain connector: http://192.168.1.146:7545
2025-05-14 17:27:47,680 - FL-Client-Ensemble - INFO - Using contract at: 0x47e7A7FAb1aEf8994b9b767E8743239D606a749A
2025-05-14 17:27:47,680 - FL-Client-Ensemble - INFO - Using dataset files: ./data/client-2_train.txt and ./data/client-2_test.txt
2025-05-14 17:27:48,087 - FL-Client-Ensemble - INFO - Dataset loaded - Features: 33
2025-05-14 17:27:48,087 - FL-Client-Ensemble - INFO - Train samples: 5000, Test samples: 5004
2025-05-14 17:27:48,087 - FL-Client-Ensemble - INFO - Positive class ratio: 12.94%
2025-05-14 17:27:48,088 - FL-Client-Ensemble - INFO - Initialized client-2 with GA-Stacking pipeline
2025-05-14 17:27:48,088 - FL-Client-Ensemble - INFO - IPFS node: http://127.0.0.1:5001/api/v0
2025-05-14 17:27:48,214 - FL-Client-Ensemble - INFO - Client 0x73CDd275BeB83388A2eB8A6b10C5E1Db7b1f1e0b is authorized on the blockchain âœ…
2025-05-14 17:27:48,223 - flwr - DEBUG - Opened insecure gRPC connection (no certificates were passed)
2025-05-14 17:27:48,228 - flwr - DEBUG - ChannelConnectivity.IDLE
2025-05-14 17:27:48,233 - flwr - DEBUG - ChannelConnectivity.CONNECTING
2025-05-14 17:27:48,233 - flwr - DEBUG - ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1747243668.249769   75051 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
INFO :      
2025-05-14 17:27:48,273 - flwr - INFO - 
INFO :      Received: train message d26f7985-79a3-4c1d-8ad9-8f2c410213612025-05-14 17:27:48,274 - flwr - INFO - Received: train message d26f7985-79a3-4c1d-8ad9-8f2c41021361
WARNING :   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.
2025-05-14 17:27:48,275 - flwr - WARNING - Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.
2025-05-14 17:27:48,352 - FL-Client-Ensemble - INFO - Split data: train=4000 samples, val=1000 samples
2025-05-14 17:27:48,352 - FL-Client-Ensemble - INFO - Performing GA-Stacking optimization
Generating meta-features...
I0000 00:00:1747243675.676084   75043 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
I0000 00:00:1747243675.705722   75043 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers

[LightGBM] [Info] Number of positive: 414, number of negative: 2786
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012674 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 3200, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129375 -> initscore=-1.906496
[LightGBM] [Info] Start training from score -1.906496
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Number of positive: 414, number of negative: 2786
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 3200, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129375 -> initscore=-1.906496
[LightGBM] [Info] Start training from score -1.906496
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Number of positive: 414, number of negative: 2786
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 3200, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129375 -> initscore=-1.906496
[LightGBM] [Info] Start training from score -1.906496
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Number of positive: 415, number of negative: 2785
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017888 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 3200, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129688 -> initscore=-1.903725
[LightGBM] [Info] Start training from score -1.903725
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Number of positive: 415, number of negative: 2785
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016671 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 3200, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129688 -> initscore=-1.903725
[LightGBM] [Info] Start training from score -1.903725
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:30:58] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:31:03] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:31:08] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:31:10] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:31:16] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
Training base models...
[LightGBM] [Info] Number of positive: 518, number of negative: 3482
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004837 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8163
[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129500 -> initscore=-1.905387
[LightGBM] [Info] Start training from score -1.905387
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:32:09] WARNING: /workspace/src/learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
Generating validation meta-features...
Running GA optimization...
Gen 1/2 - best auc: 1.0000
Gen 2/2 - best auc: 1.0000
AUC : 1.0
F1  : 1.0
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       871
           1       1.00      1.00      1.00       129

    accuracy                           1.00      1000
   macro avg       1.00      1.00      1.00      1000
weighted avg       1.00      1.00      1.00      1000

2025-05-14 17:32:14,854 - FL-Client-Ensemble - ERROR - Error in GA-Stacking: name 'roc_auc_score' is not defined
AUC : 0.9973968762515018
F1  : 0.888888888888889
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4994
           1       1.00      0.80      0.89        10

    accuracy                           1.00      5004
   macro avg       1.00      0.90      0.94      5004
weighted avg       1.00      1.00      1.00      5004

2025-05-14 17:32:15,231 - FL-Client-Ensemble - ERROR - Failed to save ensemble to IPFS: 'NoneType' object has no attribute 'get'
ERROR :     Client raised an exception.
Traceback (most recent call last):
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/app.py", line 526, in start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 143, in __call__
    return self._call(message, context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 126, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 129, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client.py", line 255, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 259, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client.py", line 407, in fit
    metrics["ensemble_size"] = len(self.ensemble_state.get("model_names", [])) if hasattr(self, 'ensemble_state') else 0
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-14 17:32:15,238 - flwr - ERROR - Client raised an exception.
Traceback (most recent call last):
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/app.py", line 526, in start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 143, in __call__
    return self._call(message, context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 126, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 129, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client.py", line 255, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 259, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client.py", line 407, in fit
    metrics["ensemble_size"] = len(self.ensemble_state.get("model_names", [])) if hasattr(self, 'ensemble_state') else 0
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-14 17:32:15,282 - flwr - DEBUG - gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 765, in <module>
    start_client(
  File "client.py", line 731, in start_client
    fl.client.start_client(server_address=server_address, client=client)  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/app.py", line 175, in start_client
    start_client_internal(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/app.py", line 533, in start_client_internal
    raise ex
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/app.py", line 526, in start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 143, in __call__
    return self._call(message, context)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client_app.py", line 126, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 129, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/client.py", line 255, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/cam/v2-flw/backend/venv/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 259, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client.py", line 407, in fit
    metrics["ensemble_size"] = len(self.ensemble_state.get("model_names", [])) if hasattr(self, 'ensemble_state') else 0
AttributeError: 'NoneType' object has no attribute 'get'